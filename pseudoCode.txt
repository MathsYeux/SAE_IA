// Exemple d'utilisation du MLP
int[] couches = {inputSize, hiddenLayerSize, outputSize}; // Définir la taille de chaque couche
double learningRate = 0.01; // Définir le taux d'apprentissage
TransferFunction activationFunction = new SigmoidFunction(); // Utiliser la fonction d'activation souhaitée

// Initialiser le MLP
MLP mlp = new MLP(couches, learningRate, activationFunction);

// Données d'entraînement
double[][] trainingInputs = {...}; // Définir les données d'entrée d'entraînement
double[][] trainingOutputs = {...}; // Définir les données de sortie d'entraînement

// Entraînement du MLP
for (int epoch = 0; epoch < numEpochs; epoch++) {
    double totalError = 0.0;

    // Itérer sur chaque exemple d'entraînement
    for (int example = 0; example < numExamples; example++) {
        // Forward pass (exécution)
        double[] input = trainingInputs[example];
        double[] targetOutput = trainingOutputs[example];
        double[] output = mlp.execute(input);

        // Backward pass (rétropropagation)
        double error = mlp.backPropagate(input, targetOutput);
        totalError += error;
    }

    // Calculer l'erreur moyenne pour cette époque
    double averageError = totalError / numExamples;

    // Afficher l'erreur moyenne pour le suivi
    print("Epoch " + epoch + ", Average Error: " + averageError);
}

// Test du MLP sur de nouvelles données
double[] newInput = {...}; // Définir vos nouvelles données d'entrée
double[] prediction = mlp.execute(newInput);

// Afficher la prédiction
print("Prediction: " + Arrays.toString(prediction));
